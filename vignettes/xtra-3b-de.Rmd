---
title: Detecting differental expression from single-cell RNA-seq data
author: 
- name: Aaron T. L. Lun
  affiliation: &CRUK Cancer Research UK Cambridge Institute, Li Ka Shing Centre, Robinson Way, Cambridge CB2 0RE, United Kingdom
date: "`r Sys.Date()`"
vignette: >
  %\VignetteIndexEntry{10. Detecting differential expression}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}    
output: 
  BiocStyle::html_document:
    titlecaps: false
    toc_float: true
bibliography: ref.bib
---
    
```{r style, echo=FALSE, results='hide', message=FALSE}
library(BiocStyle)
library(knitr)
opts_chunk$set(error=FALSE, message=FALSE, warning=FALSE)
opts_chunk$set(fig.asp=1)
```

# Caveats with interpreting DE p-values

## Data dredging from clustering

It is worth noting that all of our DE strategies for detecting marker genes between clusters are statistically flawed to some extent.
The DE analysis is performed on the same data used to obtain the clusters, which represents "data dredging" (also known as fishing or data snooping).
The hypothesis of interest - that are there differences between clusters? - is formulated from the data, 
so we are more likely to get a positive result when we re-use the data set to test that hypothesis.

The practical effect of data dredging is best illustrated with a simple simulation.
We simulate i.i.d. normal values, perform k-means clustering and test for DE between clusters of cells with `findMarkers()`.
The resulting distribution of $p$-values is heavily skewed towards low values (Figure \@ref(fig:pval-dist)).
Thus, we can detect "significant" differences between clusters even in the absence of any real substructure in the data.
This effect arises from the fact that clustering, by definition, yields groups of cells that differ in their coordinates in expression space. 
Testing for DE genes between clusters will inevitably yield some significant results as that is how the clusters were defined in the first place.

```{r pval-dist, fig.cap="Distribution of p-values from a DE analysis between two clusters in a simulation with no true subpopulation structure."}
set.seed(0)
library(scran)
y <- matrix(rnorm(100000), ncol=200)
clusters <- kmeans(t(y), centers=2)$cluster
out <- findMarkers(y, clusters)
hist(out[[1]]$p.value, col="grey80", xlab="p-value")
```

By and large, this effect does not cause problems for marker gene detection as the DE statistics from `findMarkers()` and counterparts are primarily used for ranking.
It does become an issue when the $p$-values are used to define "significant differences" between clusters with respect to an error rate threshold.
Meaningful interpretation of error rates require consideration of the long-run behaviour, i.e., the rate of incorrect rejections if the experiment were repeated many times.
The concept of statistical significance for differences between clusters is not applicable if clusters are not stably reproducible across (hypothetical) replicate experiments.

To overcome this conceptual hurdle, we need to annotate our clusters based on a few marker genes.
This allows us to use the annotated clusters as proxies for the true (and presumably reproducible) biological subpopulations.
We might then be tempted to interpret the significant genes as being DE between subpopulations.
However, this would result in loss of error control when the clusters are not stable, due to overfitting of the cluster definitions for true null genes.
This effect is exacerbated as the clusters become more unstable, e.g., due to poor separation between the underlying populations.

## Considering sample effects

The naive application of DE analysis methods will treat counts from the same cluster of cells as replicate observations.
This is not the most relevant level of replication when cells are derived from the same biological sample (i.e., cell culture, animal or patient).
DE analyses that treat cells as replicates fail to properly model the sample-to-sample variability [@lun2017overcoming].
The latter is arguably the more important level of replication as different samples will necessarily be generated if the experiment is to be replicated.
Indeed, the use of cells as replicates only masks the fact that the sample size is actually one in an experiment involving a single biological sample.

The "most correct" strategy for accommodating two levels of replication is to use a (generalized) linear mixed model.
However, these are difficult to implement from both a theoretical and practical perspective - see [here](https://bbolker.github.io/mixedmodels-misc/glmmFAQ.html) for an in-depth discussion.
A faster approach is to use a summation strategy [@lun2017overcoming], where all cells in each combination of batch and condition/cluster are summed together.
This yields a single pseudo-bulk sample per combination for which standard methods like `r Biocpkg("edgeR")` or `r Biocpkg("limma")` can be applied.

We demonstrate this procedure on the 416B data set from the `r Biocpkg("simpleSingleCell", vignette="work-1-reads.html", label="previous workflow")`.
We first create a factor containing all combinations of the per-cell factors of interest.
Here, the factors of interest are the assigned cluster and the plate of origin for each cell^[Cluster is nested in oncogene induction status so that latter will not be used here.].
All cells from one plate with the same oncogene induction status were obtained from the same biological sample.

```{r}
library(SingleCellExperiment)
sce.416b <- readRDS("416B_data.rds")
combos <- with(colData(sce.416b), paste(cluster, Plate, sep="."))
(num <- table(combos))
```

We sum the count profiles for all cells in each level of `combos`^[After dividing by size factors in `sce.416b`, to avoid unnecessary variability due to technical scaling biases.].
This yields a set of pseudo-bulk samples that are more amenable to standard DE analysis as the counts are higher and per-observation variance is lower.
It also ensures that the variance is modelled across samples rather than across cells.
Each sample is represented no more than once for each condition in the `summed` matrix, avoiding problems from unmodelled correlations between samples. 

```{r}
library(scater)
sce.416b <- normalize(sce.416b, return_log=FALSE)

library(DelayedMatrixStats) 
summed <- colsum(normcounts(sce.416b), group=combos)
head(summed)
```

Finally, we perform a standard `r Biocpkg("edgeR")` analysis using the quasi-likelihood framework [@chen2016from].
We ignore spike-in transcripts and low-abundance genes;
set up the design matrix so that the plate of origin is an additive effect;
weight each pseudo-bulk count by the number of cells used to compute it; 
and test for DE between the first two clusters.

```{r}
library(edgeR)
y <- DGEList(summed)
y <- y[aveLogCPM(y) > 1 & !isSpike(sce.416b),]
y <- calcNormFactors(y)

# Adding a matrix of sample weights.
w <- as.numeric(num)[match(colnames(y), names(num))]
y$weights <- makeCompressedMatrix(w, dim(y), byrow=TRUE)

# Building the design matrix.
sum.factors <- strsplit(colnames(summed), split="\\.")
sum.clust <- unlist(lapply(sum.factors, "[[", i=1))
sum.plate <- unlist(lapply(sum.factors, "[[", i=2))
design <- model.matrix(~0 + sum.clust + sum.plate)

# Running through the remaining edgeR functions.
y <- estimateDisp(y, design)
fit <- glmQLFit(y, design, robust=TRUE)
res <- glmQLFTest(fit, contrast=c(1, -1, 0, 0, 0, 0))
topTags(res)
summary(decideTests(res))
```

DE analysis on summed pseudo-bulk counts does not explicitly penalize DE genes that are highly variable across cells within each sample.
One could argue that this is undesirable as DE genes with low expression variance across cells are more discriminative and should be more highly ranked.
In practice, this is less of an issue than might be expected.
The effect size will naturally be smaller when cell-to-cell expression is highly variable, simply because the means of each group must be closer together when the distributions mix.
The standard error of each sum will also be naturally higher, which contributes to increased variability across sums.
These effects mean that the analysis on summed counts implicitly favours DE genes with low cell-to-cell variance.

**Comments from Aaron:**

- Note that the data dredging problem mentioned previously is an orthogonal issue to variance modelling.
This will not be resolved by performing summation on data with empirically defined clusters.
Of course, the summation approach can also be easily used with _a priori_ defined groups for which data dredging is not a problem.

# References
